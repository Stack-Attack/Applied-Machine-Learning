{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q4.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"INYCYdt7V5RV","outputId":"95322211-d43b-4240-f28e-8320fcfebd84","executionInfo":{"status":"ok","timestamp":1553194210664,"user_tz":240,"elapsed":1607,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["'''\n","#Train a simple deep CNN on the CIFAR10 small images dataset.\n","It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n","(it's still underfitting at that point, though).\n","'''\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","import pandas as pd\n","import os\n","from google.colab import files"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"8c699g72G-26","colab_type":"code","colab":{}},"cell_type":"code","source":["data = {}"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"3dtyq0eNV5Rb","outputId":"5ef216d0-99ad-4f64-bde5-031abc1d91dd","executionInfo":{"status":"ok","timestamp":1553197968912,"user_tz":240,"elapsed":2319966,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":1820}},"cell_type":"code","source":["\n","\n","batch_size = 32\n","num_classes = 10\n","epochs = 50\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['Dropout & Augment'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Using real-time data augmentation.\n","Epoch 1/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 1.8366 - acc: 0.3241 - val_loss: 1.5355 - val_acc: 0.4440\n","Epoch 2/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.5595 - acc: 0.4306 - val_loss: 1.5195 - val_acc: 0.4697\n","Epoch 3/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 1.4462 - acc: 0.4794 - val_loss: 1.2670 - val_acc: 0.5456\n","Epoch 4/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 1.3735 - acc: 0.5083 - val_loss: 1.1776 - val_acc: 0.5789\n","Epoch 5/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.3029 - acc: 0.5346 - val_loss: 1.1230 - val_acc: 0.6028\n","Epoch 6/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.2442 - acc: 0.5575 - val_loss: 1.0515 - val_acc: 0.6308\n","Epoch 7/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.1951 - acc: 0.5755 - val_loss: 1.2103 - val_acc: 0.5913\n","Epoch 8/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.1456 - acc: 0.5956 - val_loss: 1.0744 - val_acc: 0.6181\n","Epoch 9/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.1091 - acc: 0.6085 - val_loss: 0.9732 - val_acc: 0.6567\n","Epoch 10/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 1.0758 - acc: 0.6207 - val_loss: 0.9583 - val_acc: 0.6656\n","Epoch 11/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 1.0493 - acc: 0.6317 - val_loss: 0.9560 - val_acc: 0.6733\n","Epoch 12/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.0207 - acc: 0.6421 - val_loss: 1.0577 - val_acc: 0.6375\n","Epoch 13/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.9997 - acc: 0.6499 - val_loss: 0.8627 - val_acc: 0.7012\n","Epoch 14/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.9795 - acc: 0.6582 - val_loss: 0.9636 - val_acc: 0.6748\n","Epoch 15/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.9594 - acc: 0.6645 - val_loss: 0.9118 - val_acc: 0.6890\n","Epoch 16/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.9439 - acc: 0.6706 - val_loss: 0.8114 - val_acc: 0.7225\n","Epoch 17/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.9331 - acc: 0.6759 - val_loss: 0.7720 - val_acc: 0.7397\n","Epoch 18/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.9215 - acc: 0.6789 - val_loss: 0.8585 - val_acc: 0.7019\n","Epoch 19/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.9078 - acc: 0.6849 - val_loss: 0.8511 - val_acc: 0.7140\n","Epoch 20/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.8965 - acc: 0.6904 - val_loss: 0.7814 - val_acc: 0.7386\n","Epoch 21/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.8875 - acc: 0.6920 - val_loss: 0.7749 - val_acc: 0.7387\n","Epoch 22/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.8865 - acc: 0.6941 - val_loss: 0.7754 - val_acc: 0.7354\n","Epoch 23/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8731 - acc: 0.7000 - val_loss: 0.7517 - val_acc: 0.7469\n","Epoch 24/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.8664 - acc: 0.7002 - val_loss: 0.7504 - val_acc: 0.7420\n","Epoch 25/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8532 - acc: 0.7046 - val_loss: 0.7975 - val_acc: 0.7283\n","Epoch 26/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.8531 - acc: 0.7099 - val_loss: 0.7326 - val_acc: 0.7516\n","Epoch 27/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8436 - acc: 0.7106 - val_loss: 0.7704 - val_acc: 0.7403\n","Epoch 28/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.8393 - acc: 0.7124 - val_loss: 0.7875 - val_acc: 0.7448\n","Epoch 29/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8361 - acc: 0.7143 - val_loss: 0.7504 - val_acc: 0.7509\n","Epoch 30/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8284 - acc: 0.7204 - val_loss: 0.7897 - val_acc: 0.7354\n","Epoch 31/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8252 - acc: 0.7189 - val_loss: 0.7887 - val_acc: 0.7426\n","Epoch 32/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8281 - acc: 0.7158 - val_loss: 0.7303 - val_acc: 0.7606\n","Epoch 33/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8200 - acc: 0.7202 - val_loss: 0.7361 - val_acc: 0.7531\n","Epoch 34/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8155 - acc: 0.7215 - val_loss: 0.7085 - val_acc: 0.7672\n","Epoch 35/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8146 - acc: 0.7228 - val_loss: 0.7074 - val_acc: 0.7630\n","Epoch 36/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8156 - acc: 0.7228 - val_loss: 0.7322 - val_acc: 0.7503\n","Epoch 37/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8138 - acc: 0.7232 - val_loss: 0.7902 - val_acc: 0.7394\n","Epoch 38/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8147 - acc: 0.7235 - val_loss: 0.7398 - val_acc: 0.7513\n","Epoch 39/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.8073 - acc: 0.7254 - val_loss: 0.7838 - val_acc: 0.7419\n","Epoch 40/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.8041 - acc: 0.7270 - val_loss: 0.7534 - val_acc: 0.7538\n","Epoch 41/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.8010 - acc: 0.7291 - val_loss: 0.8092 - val_acc: 0.7426\n","Epoch 42/50\n","1563/1562 [==============================] - 47s 30ms/step - loss: 0.7935 - acc: 0.7302 - val_loss: 0.7679 - val_acc: 0.7515\n","Epoch 43/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.7956 - acc: 0.7302 - val_loss: 0.8352 - val_acc: 0.7352\n","Epoch 44/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.7893 - acc: 0.7314 - val_loss: 0.7611 - val_acc: 0.7467\n","Epoch 45/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.7918 - acc: 0.7337 - val_loss: 0.7247 - val_acc: 0.7561\n","Epoch 46/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.7928 - acc: 0.7312 - val_loss: 0.7242 - val_acc: 0.7563\n","Epoch 47/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.7875 - acc: 0.7329 - val_loss: 0.7191 - val_acc: 0.7587\n","Epoch 48/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.7880 - acc: 0.7319 - val_loss: 0.7260 - val_acc: 0.7597\n","Epoch 49/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.7844 - acc: 0.7340 - val_loss: 0.7249 - val_acc: 0.7563\n","Epoch 50/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.7875 - acc: 0.7345 - val_loss: 0.7722 - val_acc: 0.7423\n"],"name":"stdout"}]},{"metadata":{"id":"m_AJLab2HH3w","colab_type":"code","outputId":"c291cb98-1a7d-4165-97c8-5ee1c049bd1a","executionInfo":{"status":"ok","timestamp":1553198940862,"user_tz":240,"elapsed":3291410,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":1837}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 50\n","data_augmentation = False\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    data['Dropout'] = model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['Dropout'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Not using data augmentation.\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 20s 404us/step - loss: 1.8061 - acc: 0.3364 - val_loss: 1.5144 - val_acc: 0.4476\n","Epoch 2/50\n","50000/50000 [==============================] - 20s 391us/step - loss: 1.4913 - acc: 0.4584 - val_loss: 1.3864 - val_acc: 0.4938\n","Epoch 3/50\n","50000/50000 [==============================] - 20s 393us/step - loss: 1.3591 - acc: 0.5118 - val_loss: 1.2411 - val_acc: 0.5599\n","Epoch 4/50\n","50000/50000 [==============================] - 20s 393us/step - loss: 1.2604 - acc: 0.5505 - val_loss: 1.1488 - val_acc: 0.5962\n","Epoch 5/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 1.1797 - acc: 0.5817 - val_loss: 1.1004 - val_acc: 0.6096\n","Epoch 6/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 1.1122 - acc: 0.6090 - val_loss: 1.1209 - val_acc: 0.6068\n","Epoch 7/50\n","50000/50000 [==============================] - 20s 391us/step - loss: 1.0544 - acc: 0.6298 - val_loss: 0.9970 - val_acc: 0.6569\n","Epoch 8/50\n","50000/50000 [==============================] - 20s 392us/step - loss: 1.0051 - acc: 0.6481 - val_loss: 0.9665 - val_acc: 0.6621\n","Epoch 9/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.9675 - acc: 0.6625 - val_loss: 0.9089 - val_acc: 0.6879\n","Epoch 10/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.9329 - acc: 0.6749 - val_loss: 0.8923 - val_acc: 0.6966\n","Epoch 11/50\n","50000/50000 [==============================] - 20s 391us/step - loss: 0.9050 - acc: 0.6845 - val_loss: 0.8535 - val_acc: 0.7040\n","Epoch 12/50\n","50000/50000 [==============================] - 20s 392us/step - loss: 0.8776 - acc: 0.6946 - val_loss: 0.8434 - val_acc: 0.7098\n","Epoch 13/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.8512 - acc: 0.7058 - val_loss: 0.8165 - val_acc: 0.7170\n","Epoch 14/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.8350 - acc: 0.7090 - val_loss: 0.8204 - val_acc: 0.7176\n","Epoch 15/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.8099 - acc: 0.7173 - val_loss: 0.7944 - val_acc: 0.7302\n","Epoch 16/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.7931 - acc: 0.7268 - val_loss: 0.8519 - val_acc: 0.7063\n","Epoch 17/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.7818 - acc: 0.7305 - val_loss: 0.7545 - val_acc: 0.7378\n","Epoch 18/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.7651 - acc: 0.7356 - val_loss: 0.7528 - val_acc: 0.7401\n","Epoch 19/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.7560 - acc: 0.7393 - val_loss: 0.7434 - val_acc: 0.7452\n","Epoch 20/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.7480 - acc: 0.7428 - val_loss: 0.7682 - val_acc: 0.7411\n","Epoch 21/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.7401 - acc: 0.7462 - val_loss: 0.7320 - val_acc: 0.7540\n","Epoch 22/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.7336 - acc: 0.7492 - val_loss: 0.7458 - val_acc: 0.7490\n","Epoch 23/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.7252 - acc: 0.7526 - val_loss: 0.7049 - val_acc: 0.7627\n","Epoch 24/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.7223 - acc: 0.7528 - val_loss: 0.7047 - val_acc: 0.7594\n","Epoch 25/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.7140 - acc: 0.7583 - val_loss: 0.7092 - val_acc: 0.7623\n","Epoch 26/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.7108 - acc: 0.7584 - val_loss: 0.6934 - val_acc: 0.7681\n","Epoch 27/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.7043 - acc: 0.7593 - val_loss: 0.7091 - val_acc: 0.7634\n","Epoch 28/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.6993 - acc: 0.7629 - val_loss: 0.7409 - val_acc: 0.7528\n","Epoch 29/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6975 - acc: 0.7633 - val_loss: 0.6826 - val_acc: 0.7707\n","Epoch 30/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.6899 - acc: 0.7667 - val_loss: 0.7075 - val_acc: 0.7617\n","Epoch 31/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.6843 - acc: 0.7680 - val_loss: 0.6719 - val_acc: 0.7731\n","Epoch 32/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6802 - acc: 0.7695 - val_loss: 0.6823 - val_acc: 0.7710\n","Epoch 33/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.6778 - acc: 0.7714 - val_loss: 0.7054 - val_acc: 0.7647\n","Epoch 34/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6774 - acc: 0.7710 - val_loss: 0.6885 - val_acc: 0.7685\n","Epoch 35/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.6731 - acc: 0.7716 - val_loss: 0.7089 - val_acc: 0.7609\n","Epoch 36/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6650 - acc: 0.7740 - val_loss: 0.6691 - val_acc: 0.7726\n","Epoch 37/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.6702 - acc: 0.7739 - val_loss: 0.6720 - val_acc: 0.7772\n","Epoch 38/50\n","50000/50000 [==============================] - 19s 385us/step - loss: 0.6641 - acc: 0.7778 - val_loss: 0.6794 - val_acc: 0.7699\n","Epoch 39/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.6609 - acc: 0.7776 - val_loss: 0.6701 - val_acc: 0.7733\n","Epoch 40/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6545 - acc: 0.7807 - val_loss: 0.6644 - val_acc: 0.7773\n","Epoch 41/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6567 - acc: 0.7782 - val_loss: 0.6840 - val_acc: 0.7708\n","Epoch 42/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.6562 - acc: 0.7815 - val_loss: 0.7483 - val_acc: 0.7745\n","Epoch 43/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6548 - acc: 0.7806 - val_loss: 0.6858 - val_acc: 0.7782\n","Epoch 44/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.6474 - acc: 0.7824 - val_loss: 0.6854 - val_acc: 0.7721\n","Epoch 45/50\n","50000/50000 [==============================] - 19s 386us/step - loss: 0.6480 - acc: 0.7849 - val_loss: 0.6827 - val_acc: 0.7776\n","Epoch 46/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.6430 - acc: 0.7860 - val_loss: 0.6706 - val_acc: 0.7760\n","Epoch 47/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.6397 - acc: 0.7865 - val_loss: 0.6835 - val_acc: 0.7759\n","Epoch 48/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.6356 - acc: 0.7864 - val_loss: 0.6734 - val_acc: 0.7798\n","Epoch 49/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 0.6398 - acc: 0.7884 - val_loss: 0.6959 - val_acc: 0.7748\n","Epoch 50/50\n","50000/50000 [==============================] - 19s 388us/step - loss: 0.6334 - acc: 0.7895 - val_loss: 0.6622 - val_acc: 0.7836\n"],"name":"stdout"}]},{"metadata":{"id":"8uQ_zYsrAaZB","colab_type":"code","outputId":"2b5ba6f3-5e34-4b6e-f70d-a9515c053a69","executionInfo":{"status":"ok","timestamp":1553201228737,"user_tz":240,"elapsed":5578912,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":1820}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 50\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['Augment'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Using real-time data augmentation.\n","Epoch 1/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 1.7196 - acc: 0.3793 - val_loss: 1.4360 - val_acc: 0.4737\n","Epoch 2/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 1.4335 - acc: 0.4855 - val_loss: 1.3135 - val_acc: 0.5345\n","Epoch 3/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 1.2978 - acc: 0.5434 - val_loss: 1.1561 - val_acc: 0.5894\n","Epoch 4/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 1.1955 - acc: 0.5776 - val_loss: 1.0769 - val_acc: 0.6248\n","Epoch 5/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 1.1183 - acc: 0.6074 - val_loss: 0.9901 - val_acc: 0.6530\n","Epoch 6/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 1.0612 - acc: 0.6295 - val_loss: 0.9467 - val_acc: 0.6677\n","Epoch 7/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 1.0131 - acc: 0.6468 - val_loss: 0.9528 - val_acc: 0.6636\n","Epoch 8/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.9729 - acc: 0.6584 - val_loss: 0.9015 - val_acc: 0.6841\n","Epoch 9/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.9329 - acc: 0.6742 - val_loss: 0.9221 - val_acc: 0.6867\n","Epoch 10/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.8993 - acc: 0.6868 - val_loss: 0.8517 - val_acc: 0.7047\n","Epoch 11/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.8676 - acc: 0.6974 - val_loss: 0.7956 - val_acc: 0.7257\n","Epoch 12/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.8355 - acc: 0.7077 - val_loss: 0.8171 - val_acc: 0.7182\n","Epoch 13/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.8079 - acc: 0.7190 - val_loss: 0.8355 - val_acc: 0.7098\n","Epoch 14/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.7820 - acc: 0.7282 - val_loss: 0.7676 - val_acc: 0.7382\n","Epoch 15/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.7590 - acc: 0.7368 - val_loss: 0.7283 - val_acc: 0.7523\n","Epoch 16/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.7376 - acc: 0.7441 - val_loss: 0.8409 - val_acc: 0.7245\n","Epoch 17/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.7234 - acc: 0.7516 - val_loss: 0.7139 - val_acc: 0.7580\n","Epoch 18/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.7070 - acc: 0.7570 - val_loss: 0.6601 - val_acc: 0.7690\n","Epoch 19/50\n","1563/1562 [==============================] - 45s 29ms/step - loss: 0.6863 - acc: 0.7629 - val_loss: 0.6985 - val_acc: 0.7589\n","Epoch 20/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.6732 - acc: 0.7659 - val_loss: 0.6983 - val_acc: 0.7630\n","Epoch 21/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.6616 - acc: 0.7711 - val_loss: 0.6579 - val_acc: 0.7751\n","Epoch 22/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.6480 - acc: 0.7767 - val_loss: 0.6679 - val_acc: 0.7701\n","Epoch 23/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.6320 - acc: 0.7810 - val_loss: 0.6934 - val_acc: 0.7711\n","Epoch 24/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.6214 - acc: 0.7846 - val_loss: 0.6910 - val_acc: 0.7716\n","Epoch 25/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.6109 - acc: 0.7891 - val_loss: 0.6667 - val_acc: 0.7762\n","Epoch 26/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.6066 - acc: 0.7914 - val_loss: 0.6420 - val_acc: 0.7803\n","Epoch 27/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.5972 - acc: 0.7911 - val_loss: 0.6896 - val_acc: 0.7759\n","Epoch 28/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.5891 - acc: 0.7979 - val_loss: 0.6448 - val_acc: 0.7800\n","Epoch 29/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.5802 - acc: 0.7995 - val_loss: 0.7007 - val_acc: 0.7740\n","Epoch 30/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.5740 - acc: 0.8027 - val_loss: 0.6224 - val_acc: 0.7932\n","Epoch 31/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5609 - acc: 0.8052 - val_loss: 0.6868 - val_acc: 0.7787\n","Epoch 32/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.5601 - acc: 0.8097 - val_loss: 0.5884 - val_acc: 0.8014\n","Epoch 33/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5555 - acc: 0.8088 - val_loss: 0.6987 - val_acc: 0.7755\n","Epoch 34/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5444 - acc: 0.8116 - val_loss: 0.5903 - val_acc: 0.8040\n","Epoch 35/50\n","1563/1562 [==============================] - 46s 30ms/step - loss: 0.5391 - acc: 0.8134 - val_loss: 0.6083 - val_acc: 0.8013\n","Epoch 36/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5359 - acc: 0.8144 - val_loss: 0.6714 - val_acc: 0.7830\n","Epoch 37/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5308 - acc: 0.8179 - val_loss: 0.6062 - val_acc: 0.8009\n","Epoch 38/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5292 - acc: 0.8191 - val_loss: 0.7082 - val_acc: 0.7785\n","Epoch 39/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5257 - acc: 0.8200 - val_loss: 0.6641 - val_acc: 0.7870\n","Epoch 40/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5197 - acc: 0.8229 - val_loss: 0.5925 - val_acc: 0.8082\n","Epoch 41/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5188 - acc: 0.8227 - val_loss: 0.6630 - val_acc: 0.7854\n","Epoch 42/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5111 - acc: 0.8236 - val_loss: 0.6872 - val_acc: 0.7878\n","Epoch 43/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5109 - acc: 0.8242 - val_loss: 0.6218 - val_acc: 0.7979\n","Epoch 44/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5036 - acc: 0.8264 - val_loss: 0.6577 - val_acc: 0.7938\n","Epoch 45/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5020 - acc: 0.8258 - val_loss: 0.6672 - val_acc: 0.7904\n","Epoch 46/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5017 - acc: 0.8271 - val_loss: 0.5974 - val_acc: 0.8050\n","Epoch 47/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.5007 - acc: 0.8284 - val_loss: 0.6791 - val_acc: 0.7935\n","Epoch 48/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.4955 - acc: 0.8301 - val_loss: 0.5927 - val_acc: 0.8015\n","Epoch 49/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.4925 - acc: 0.8307 - val_loss: 0.6008 - val_acc: 0.8039\n","Epoch 50/50\n","1563/1562 [==============================] - 46s 29ms/step - loss: 0.4969 - acc: 0.8296 - val_loss: 0.6022 - val_acc: 0.8110\n"],"name":"stdout"}]},{"metadata":{"id":"rm2glI26Aao4","colab_type":"code","outputId":"ff189338-1800-4da7-86f2-209d4cb29816","executionInfo":{"status":"ok","timestamp":1553202156922,"user_tz":240,"elapsed":6506492,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":1837}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 50\n","data_augmentation = False\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    data['Neither'] = model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['Neither'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Not using data augmentation.\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/50\n","50000/50000 [==============================] - 19s 387us/step - loss: 1.6414 - acc: 0.4116 - val_loss: 1.3951 - val_acc: 0.5009\n","Epoch 2/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 1.3268 - acc: 0.5265 - val_loss: 1.2869 - val_acc: 0.5482\n","Epoch 3/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 1.1753 - acc: 0.5844 - val_loss: 1.1233 - val_acc: 0.6070\n","Epoch 4/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 1.0606 - acc: 0.6261 - val_loss: 1.0613 - val_acc: 0.6242\n","Epoch 5/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.9694 - acc: 0.6619 - val_loss: 0.9967 - val_acc: 0.6553\n","Epoch 6/50\n","50000/50000 [==============================] - 18s 370us/step - loss: 0.8924 - acc: 0.6910 - val_loss: 0.9265 - val_acc: 0.6769\n","Epoch 7/50\n","50000/50000 [==============================] - 18s 362us/step - loss: 0.8244 - acc: 0.7149 - val_loss: 0.9102 - val_acc: 0.6860\n","Epoch 8/50\n","50000/50000 [==============================] - 18s 361us/step - loss: 0.7632 - acc: 0.7358 - val_loss: 0.8994 - val_acc: 0.6844\n","Epoch 9/50\n","50000/50000 [==============================] - 18s 364us/step - loss: 0.7073 - acc: 0.7587 - val_loss: 0.9354 - val_acc: 0.6788\n","Epoch 10/50\n","50000/50000 [==============================] - 18s 366us/step - loss: 0.6551 - acc: 0.7737 - val_loss: 0.8215 - val_acc: 0.7202\n","Epoch 11/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.6024 - acc: 0.7931 - val_loss: 0.8696 - val_acc: 0.7108\n","Epoch 12/50\n","50000/50000 [==============================] - 19s 373us/step - loss: 0.5550 - acc: 0.8099 - val_loss: 0.9502 - val_acc: 0.6936\n","Epoch 13/50\n","50000/50000 [==============================] - 19s 372us/step - loss: 0.5096 - acc: 0.8259 - val_loss: 0.8150 - val_acc: 0.7332\n","Epoch 14/50\n","50000/50000 [==============================] - 19s 372us/step - loss: 0.4613 - acc: 0.8433 - val_loss: 0.8675 - val_acc: 0.7188\n","Epoch 15/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.4173 - acc: 0.8586 - val_loss: 0.8389 - val_acc: 0.7351\n","Epoch 16/50\n","50000/50000 [==============================] - 18s 369us/step - loss: 0.3738 - acc: 0.8738 - val_loss: 0.9222 - val_acc: 0.7199\n","Epoch 17/50\n","50000/50000 [==============================] - 19s 372us/step - loss: 0.3323 - acc: 0.8895 - val_loss: 0.9706 - val_acc: 0.7267\n","Epoch 18/50\n","50000/50000 [==============================] - 18s 369us/step - loss: 0.2919 - acc: 0.9035 - val_loss: 0.8996 - val_acc: 0.7409\n","Epoch 19/50\n","50000/50000 [==============================] - 19s 372us/step - loss: 0.2549 - acc: 0.9160 - val_loss: 0.9455 - val_acc: 0.7414\n","Epoch 20/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.2205 - acc: 0.9269 - val_loss: 1.0485 - val_acc: 0.7311\n","Epoch 21/50\n","50000/50000 [==============================] - 19s 373us/step - loss: 0.1877 - acc: 0.9385 - val_loss: 1.1277 - val_acc: 0.7191\n","Epoch 22/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.1589 - acc: 0.9489 - val_loss: 1.1681 - val_acc: 0.7267\n","Epoch 23/50\n","50000/50000 [==============================] - 18s 370us/step - loss: 0.1329 - acc: 0.9570 - val_loss: 1.2951 - val_acc: 0.7125\n","Epoch 24/50\n","50000/50000 [==============================] - 19s 373us/step - loss: 0.1128 - acc: 0.9637 - val_loss: 1.2197 - val_acc: 0.7353\n","Epoch 25/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0926 - acc: 0.9701 - val_loss: 1.3485 - val_acc: 0.7322\n","Epoch 26/50\n","50000/50000 [==============================] - 18s 370us/step - loss: 0.0780 - acc: 0.9755 - val_loss: 1.4067 - val_acc: 0.7321\n","Epoch 27/50\n","50000/50000 [==============================] - 19s 372us/step - loss: 0.0656 - acc: 0.9800 - val_loss: 1.4674 - val_acc: 0.7335\n","Epoch 28/50\n","50000/50000 [==============================] - 19s 372us/step - loss: 0.0571 - acc: 0.9815 - val_loss: 1.6657 - val_acc: 0.7226\n","Epoch 29/50\n","50000/50000 [==============================] - 19s 374us/step - loss: 0.0482 - acc: 0.9847 - val_loss: 1.6862 - val_acc: 0.7222\n","Epoch 30/50\n","50000/50000 [==============================] - 19s 373us/step - loss: 0.0418 - acc: 0.9869 - val_loss: 1.6623 - val_acc: 0.7344\n","Epoch 31/50\n","50000/50000 [==============================] - 19s 373us/step - loss: 0.0358 - acc: 0.9892 - val_loss: 1.6902 - val_acc: 0.7320\n","Epoch 32/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.0324 - acc: 0.9897 - val_loss: 1.8730 - val_acc: 0.7158\n","Epoch 33/50\n","50000/50000 [==============================] - 18s 370us/step - loss: 0.0302 - acc: 0.9904 - val_loss: 1.8565 - val_acc: 0.7291\n","Epoch 34/50\n","50000/50000 [==============================] - 19s 372us/step - loss: 0.0274 - acc: 0.9916 - val_loss: 1.8688 - val_acc: 0.7320\n","Epoch 35/50\n","50000/50000 [==============================] - 19s 373us/step - loss: 0.0254 - acc: 0.9919 - val_loss: 1.9817 - val_acc: 0.7265\n","Epoch 36/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.0229 - acc: 0.9928 - val_loss: 1.9373 - val_acc: 0.7319\n","Epoch 37/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.0213 - acc: 0.9932 - val_loss: 2.0369 - val_acc: 0.7299\n","Epoch 38/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 2.0493 - val_acc: 0.7332\n","Epoch 39/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0181 - acc: 0.9941 - val_loss: 2.0277 - val_acc: 0.7290\n","Epoch 40/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0188 - acc: 0.9935 - val_loss: 2.0659 - val_acc: 0.7393\n","Epoch 41/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0174 - acc: 0.9941 - val_loss: 2.2438 - val_acc: 0.7138\n","Epoch 42/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.0157 - acc: 0.9945 - val_loss: 2.2589 - val_acc: 0.7236\n","Epoch 43/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0166 - acc: 0.9946 - val_loss: 2.1530 - val_acc: 0.7269\n","Epoch 44/50\n","50000/50000 [==============================] - 18s 370us/step - loss: 0.0154 - acc: 0.9952 - val_loss: 2.2403 - val_acc: 0.7276\n","Epoch 45/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.0157 - acc: 0.9946 - val_loss: 2.1640 - val_acc: 0.7280\n","Epoch 46/50\n","50000/50000 [==============================] - 19s 373us/step - loss: 0.0149 - acc: 0.9952 - val_loss: 2.2411 - val_acc: 0.7263\n","Epoch 47/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0150 - acc: 0.9952 - val_loss: 2.1768 - val_acc: 0.7352\n","Epoch 48/50\n","50000/50000 [==============================] - 19s 371us/step - loss: 0.0152 - acc: 0.9949 - val_loss: 2.2719 - val_acc: 0.7284\n","Epoch 49/50\n","50000/50000 [==============================] - 18s 370us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 2.2621 - val_acc: 0.7317\n","Epoch 50/50\n","50000/50000 [==============================] - 19s 370us/step - loss: 0.0138 - acc: 0.9955 - val_loss: 2.2173 - val_acc: 0.7295\n"],"name":"stdout"}]},{"metadata":{"id":"I0dVTKDT7d8G","colab_type":"code","outputId":"f7918a39-ae21-4866-88c7-8655c815aa53","executionInfo":{"status":"ok","timestamp":1553202156924,"user_tz":240,"elapsed":6501092,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"cell_type":"code","source":["data"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Augment': <keras.callbacks.History at 0x7fc21c568c18>,\n"," 'Dropout': <keras.callbacks.History at 0x7fc21cbe7ba8>,\n"," 'Dropout & Augment': <keras.callbacks.History at 0x7fc21ba88ba8>,\n"," 'Neither': <keras.callbacks.History at 0x7fc21b076780>}"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"colab_type":"code","id":"XB0c92kzV5Rg","outputId":"8e240762-e286-4980-8af8-b79c685ebff3","executionInfo":{"status":"ok","timestamp":1553040762361,"user_tz":240,"elapsed":474596,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# Save model and weights\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","model_path = os.path.join(save_dir, model_name)\n","model.save(model_path)\n","print('Saved trained model at %s ' % model_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"CZs2mDmGV5Rj","outputId":"08650f2a-9a61-4706-f944-dcfcd9416b2f","executionInfo":{"status":"ok","timestamp":1553040763639,"user_tz":240,"elapsed":475722,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["# Score trained model.\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 2s 150us/step\n","Test loss: 0.9727954257965088\n","Test accuracy: 0.6554\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"zcuvptPLXnP2"},"cell_type":"markdown","source":["# Dense"]},{"metadata":{"colab_type":"code","id":"_U7lcieKV5Ro","scrolled":true,"outputId":"75ffdfb7-bc77-45f0-9e93-c5e74f409e77","executionInfo":{"status":"ok","timestamp":1553118183917,"user_tz":240,"elapsed":348575,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":433}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 10\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","model.add(Flatten(input_shape=x_train.shape[1:]))\n","\n","\n","#model.add(Dense(512))\n","#model.add(Activation('relu'))\n","#model.add(Dropout(0.5))\n","\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['DNN_0'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)\n","   "],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Using real-time data augmentation.\n","Epoch 1/10\n","1563/1562 [==============================] - 36s 23ms/step - loss: 2.0153 - acc: 0.2787 - val_loss: 1.8835 - val_acc: 0.3371\n","Epoch 2/10\n","1563/1562 [==============================] - 37s 23ms/step - loss: 1.9048 - acc: 0.3276 - val_loss: 1.8388 - val_acc: 0.3609\n","Epoch 3/10\n","1563/1562 [==============================] - 35s 22ms/step - loss: 1.8788 - acc: 0.3395 - val_loss: 1.8197 - val_acc: 0.3597\n","Epoch 4/10\n","1563/1562 [==============================] - 34s 22ms/step - loss: 1.8639 - acc: 0.3465 - val_loss: 1.8218 - val_acc: 0.3625\n","Epoch 5/10\n","1563/1562 [==============================] - 34s 22ms/step - loss: 1.8546 - acc: 0.3486 - val_loss: 1.8119 - val_acc: 0.3647\n","Epoch 6/10\n","1563/1562 [==============================] - 34s 22ms/step - loss: 1.8470 - acc: 0.3533 - val_loss: 1.7838 - val_acc: 0.3769\n","Epoch 7/10\n","1563/1562 [==============================] - 34s 22ms/step - loss: 1.8425 - acc: 0.3555 - val_loss: 1.7709 - val_acc: 0.3866\n","Epoch 8/10\n","1563/1562 [==============================] - 34s 22ms/step - loss: 1.8374 - acc: 0.3586 - val_loss: 1.7799 - val_acc: 0.3777\n","Epoch 9/10\n","1563/1562 [==============================] - 35s 22ms/step - loss: 1.8327 - acc: 0.3599 - val_loss: 1.7689 - val_acc: 0.3871\n","Epoch 10/10\n","1563/1562 [==============================] - 35s 22ms/step - loss: 1.8301 - acc: 0.3601 - val_loss: 1.7650 - val_acc: 0.3880\n"],"name":"stdout"}]},{"metadata":{"id":"hWEbqvn6HTgD","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"7wQRcjoRnqTS","colab_type":"text"},"cell_type":"markdown","source":["# Dense 1"]},{"metadata":{"id":"0a9U9udmnqTT","colab_type":"code","outputId":"9a1715b4-c5b1-4713-d70c-18488a76f294","executionInfo":{"status":"ok","timestamp":1553118552320,"user_tz":240,"elapsed":714165,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":433}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 10\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","model.add(Flatten(input_shape=x_train.shape[1:]))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['DNN_1'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Using real-time data augmentation.\n","Epoch 1/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 2.0160 - acc: 0.2694 - val_loss: 1.8232 - val_acc: 0.3604\n","Epoch 2/10\n","1563/1562 [==============================] - 36s 23ms/step - loss: 1.8886 - acc: 0.3219 - val_loss: 1.7643 - val_acc: 0.3648\n","Epoch 3/10\n","1563/1562 [==============================] - 36s 23ms/step - loss: 1.8408 - acc: 0.3400 - val_loss: 1.7096 - val_acc: 0.3990\n","Epoch 4/10\n","1563/1562 [==============================] - 36s 23ms/step - loss: 1.8084 - acc: 0.3530 - val_loss: 1.6532 - val_acc: 0.4278\n","Epoch 5/10\n","1563/1562 [==============================] - 37s 23ms/step - loss: 1.7787 - acc: 0.3654 - val_loss: 1.6221 - val_acc: 0.4308\n","Epoch 6/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.7683 - acc: 0.3712 - val_loss: 1.6011 - val_acc: 0.4352\n","Epoch 7/10\n","1563/1562 [==============================] - 36s 23ms/step - loss: 1.7510 - acc: 0.3744 - val_loss: 1.6082 - val_acc: 0.4348\n","Epoch 8/10\n","1563/1562 [==============================] - 36s 23ms/step - loss: 1.7413 - acc: 0.3806 - val_loss: 1.5867 - val_acc: 0.4420\n","Epoch 9/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.7294 - acc: 0.3861 - val_loss: 1.5768 - val_acc: 0.4430\n","Epoch 10/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.7228 - acc: 0.3867 - val_loss: 1.5668 - val_acc: 0.4552\n"],"name":"stdout"}]},{"metadata":{"id":"8Fa2-ePhPSA7","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xSFD4fTwnqTW","colab_type":"text"},"cell_type":"markdown","source":["# Dense 2"]},{"metadata":{"id":"470CYQjhnqTW","colab_type":"code","outputId":"8b4490d7-b5ec-43f7-f264-68d826386d47","executionInfo":{"status":"ok","timestamp":1553118924536,"user_tz":240,"elapsed":1078773,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":433}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 10\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","model.add(Flatten(input_shape=x_train.shape[1:]))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['DNN_2'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Using real-time data augmentation.\n","Epoch 1/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 2.0975 - acc: 0.2258 - val_loss: 1.8672 - val_acc: 0.3282\n","Epoch 2/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9522 - acc: 0.2881 - val_loss: 1.8146 - val_acc: 0.3557\n","Epoch 3/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9096 - acc: 0.3082 - val_loss: 1.7532 - val_acc: 0.3746\n","Epoch 4/10\n","1563/1562 [==============================] - 37s 23ms/step - loss: 1.8798 - acc: 0.3226 - val_loss: 1.7077 - val_acc: 0.4023\n","Epoch 5/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.8610 - acc: 0.3298 - val_loss: 1.7079 - val_acc: 0.4073\n","Epoch 6/10\n","1563/1562 [==============================] - 36s 23ms/step - loss: 1.8457 - acc: 0.3397 - val_loss: 1.6684 - val_acc: 0.4105\n","Epoch 7/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.8302 - acc: 0.3432 - val_loss: 1.6302 - val_acc: 0.4376\n","Epoch 8/10\n","1563/1562 [==============================] - 38s 25ms/step - loss: 1.8195 - acc: 0.3478 - val_loss: 1.6404 - val_acc: 0.4251\n","Epoch 9/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.8122 - acc: 0.3525 - val_loss: 1.6249 - val_acc: 0.4355\n","Epoch 10/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.8079 - acc: 0.3553 - val_loss: 1.6170 - val_acc: 0.4274\n"],"name":"stdout"}]},{"metadata":{"id":"ZlQ5WAS0nqTY","colab_type":"text"},"cell_type":"markdown","source":["# Dense 3"]},{"metadata":{"id":"-gDZiDWPnqTZ","colab_type":"code","outputId":"c1dcde9f-1234-45e9-e67a-7aad603f8522","executionInfo":{"status":"ok","timestamp":1553119303091,"user_tz":240,"elapsed":1455599,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":433}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 10\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","model.add(Flatten(input_shape=x_train.shape[1:]))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['DNN_3'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Using real-time data augmentation.\n","Epoch 1/10\n","1563/1562 [==============================] - 39s 25ms/step - loss: 2.1532 - acc: 0.1888 - val_loss: 1.9382 - val_acc: 0.3077\n","Epoch 2/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 2.0022 - acc: 0.2588 - val_loss: 1.8683 - val_acc: 0.3252\n","Epoch 3/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9478 - acc: 0.2911 - val_loss: 1.7931 - val_acc: 0.3744\n","Epoch 4/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9178 - acc: 0.3008 - val_loss: 1.7528 - val_acc: 0.3798\n","Epoch 5/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 1.8955 - acc: 0.3119 - val_loss: 1.7987 - val_acc: 0.3712\n","Epoch 6/10\n","1563/1562 [==============================] - 39s 25ms/step - loss: 1.8837 - acc: 0.3192 - val_loss: 1.7254 - val_acc: 0.3976\n","Epoch 7/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.8664 - acc: 0.3274 - val_loss: 1.7154 - val_acc: 0.4000\n","Epoch 8/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.8538 - acc: 0.3320 - val_loss: 1.6928 - val_acc: 0.4260\n","Epoch 9/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 1.8490 - acc: 0.3328 - val_loss: 1.7435 - val_acc: 0.4114\n","Epoch 10/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.8344 - acc: 0.3400 - val_loss: 1.7127 - val_acc: 0.4202\n"],"name":"stdout"}]},{"metadata":{"id":"-zhMQi7InqTc","colab_type":"text"},"cell_type":"markdown","source":["# Dense 4"]},{"metadata":{"id":"KE6I2uD4nqTd","colab_type":"code","outputId":"2eeeb3be-5d5e-4931-95a5-1fa3eab83af9","executionInfo":{"status":"ok","timestamp":1553119683597,"user_tz":240,"elapsed":1833955,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":433}},"cell_type":"code","source":["batch_size = 32\n","num_classes = 10\n","epochs = 10\n","data_augmentation = True\n","num_predictions = 20\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","\n","# The data, split between train and test sets:\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","\n","model.add(Flatten(input_shape=x_train.shape[1:]))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","\n","# initiate RMSprop optimizer\n","opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n","\n","# Let's train the model using RMSprop\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","if not data_augmentation:\n","    print('Not using data augmentation.')\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(x_test, y_test),\n","              shuffle=True)\n","else:\n","    print('Using real-time data augmentation.')\n","    # This will do preprocessing and realtime data augmentation:\n","    datagen = ImageDataGenerator(\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n","        # randomly shift images horizontally (fraction of total width)\n","        width_shift_range=0.1,\n","        # randomly shift images vertically (fraction of total height)\n","        height_shift_range=0.1,\n","        shear_range=0.,  # set range for random shear\n","        zoom_range=0.,  # set range for random zoom\n","        channel_shift_range=0.,  # set range for random channel shifts\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","    # Compute quantities required for feature-wise normalization\n","    # (std, mean, and principal components if ZCA whitening is applied).\n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    data['DNN_4'] = model.fit_generator(datagen.flow(x_train, y_train,\n","                                     batch_size=batch_size),\n","                        epochs=epochs,\n","                        steps_per_epoch=len(x_train)/batch_size,\n","                        validation_data=(x_test, y_test),\n","                        workers=4)\n","    \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","Using real-time data augmentation.\n","Epoch 1/10\n","1563/1562 [==============================] - 39s 25ms/step - loss: 2.2135 - acc: 0.1573 - val_loss: 2.0512 - val_acc: 0.2358\n","Epoch 2/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 2.0577 - acc: 0.2221 - val_loss: 1.9292 - val_acc: 0.2941\n","Epoch 3/10\n","1563/1562 [==============================] - 39s 25ms/step - loss: 2.0045 - acc: 0.2532 - val_loss: 1.8799 - val_acc: 0.3331\n","Epoch 4/10\n","1563/1562 [==============================] - 39s 25ms/step - loss: 1.9756 - acc: 0.2722 - val_loss: 1.8954 - val_acc: 0.3280\n","Epoch 5/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9549 - acc: 0.2806 - val_loss: 1.8202 - val_acc: 0.3582\n","Epoch 6/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9382 - acc: 0.2885 - val_loss: 1.8485 - val_acc: 0.3652\n","Epoch 7/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 1.9201 - acc: 0.2955 - val_loss: 1.8764 - val_acc: 0.3508\n","Epoch 8/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9134 - acc: 0.3009 - val_loss: 1.9050 - val_acc: 0.3375\n","Epoch 9/10\n","1563/1562 [==============================] - 38s 24ms/step - loss: 1.9061 - acc: 0.3010 - val_loss: 1.8713 - val_acc: 0.3594\n","Epoch 10/10\n","1563/1562 [==============================] - 37s 24ms/step - loss: 1.9007 - acc: 0.3063 - val_loss: 1.9178 - val_acc: 0.3207\n"],"name":"stdout"}]},{"metadata":{"id":"c_C0-OO1PVpw","colab_type":"code","colab":{}},"cell_type":"code","source":["results = {}\n","for h in data:\n","  results[h] = data[h].history['acc']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W-G-eMkWLa9y","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"mGmeIe4VLJMX","colab_type":"code","outputId":"c993cde8-4f0e-4143-9e3b-7e0797a9189c","executionInfo":{"status":"ok","timestamp":1553203115922,"user_tz":240,"elapsed":499,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"cell_type":"code","source":["data"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Augment': <keras.callbacks.History at 0x7fc21c568c18>,\n"," 'Dropout': <keras.callbacks.History at 0x7fc21cbe7ba8>,\n"," 'Dropout & Augment': <keras.callbacks.History at 0x7fc21ba88ba8>,\n"," 'Neither': <keras.callbacks.History at 0x7fc21b076780>}"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"L9YRTRDMlwvX","colab_type":"code","outputId":"15921077-4065-438b-b956-7a10c5eb3cdc","executionInfo":{"status":"ok","timestamp":1553203209407,"user_tz":240,"elapsed":2144,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":377}},"cell_type":"code","source":["#Create and save plots\n","q1_results_test = pd.DataFrame.from_dict(results)\n","q1_results_test.index +=1\n","plot = q1_results_test.plot.line(title='CNN Training Accuracy: Augmentation & Dropout')\n","plot.set_xlabel(\"Epochs\")\n","plot.set_ylabel(\"Training Accuracy\")\n","\n","#Display plot in Jupyter\n","plot\n","\n","#Save plot\n","fig = plot.get_figure()\n","fig.savefig(\"Q4_c_test.pdf\")\n","files.download(\"Q4_c_test.pdf\")"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZgIPKiUdZkFRMwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"EgZYBYM8maZ8","colab_type":"code","outputId":"7c90de18-d576-409c-aa4f-bad06f782c34","executionInfo":{"status":"ok","timestamp":1553043406801,"user_tz":240,"elapsed":462,"user":{"displayName":"Kyle Robinson","photoUrl":"https://lh4.googleusercontent.com/-KurUZCdrIdc/AAAAAAAAAAI/AAAAAAAApGM/-_NzNG_K1HI/s64/photo.jpg","userId":"11768981797328225424"}},"colab":{"base_uri":"https://localhost:8080/","height":1057}},"cell_type":"code","source":["results"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'CNN': [0.4313,\n","  0.5,\n","  0.527,\n","  0.5447,\n","  0.5394,\n","  0.5999,\n","  0.5741,\n","  0.6171,\n","  0.652,\n","  0.6554],\n"," 'DNN_0': [0.3829,\n","  0.4176,\n","  0.4451,\n","  0.4998,\n","  0.5134,\n","  0.5549,\n","  0.5862,\n","  0.5936,\n","  0.5977,\n","  0.6171],\n"," 'DNN_1': [0.3923,\n","  0.448,\n","  0.4867,\n","  0.4966,\n","  0.5018,\n","  0.5148,\n","  0.5163,\n","  0.5226,\n","  0.53,\n","  0.5329],\n"," 'DNN_2': [0.3401,\n","  0.4187,\n","  0.4527,\n","  0.4763,\n","  0.4875,\n","  0.4909,\n","  0.5032,\n","  0.514,\n","  0.5119,\n","  0.5163],\n"," 'DNN_3': [0.3227,\n","  0.3858,\n","  0.4262,\n","  0.4473,\n","  0.4645,\n","  0.4793,\n","  0.4852,\n","  0.4902,\n","  0.504,\n","  0.5049],\n"," 'DNN_4': [0.2734,\n","  0.335,\n","  0.3884,\n","  0.4164,\n","  0.4354,\n","  0.4509,\n","  0.4597,\n","  0.4751,\n","  0.4747,\n","  0.4711]}"]},"metadata":{"tags":[]},"execution_count":58}]}]}